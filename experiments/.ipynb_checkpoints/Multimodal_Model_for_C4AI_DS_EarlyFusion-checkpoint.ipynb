{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1648474977375,
     "user": {
      "displayName": "Victor Machado Gonzaga",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14128796530531354520"
     },
     "user_tz": 180
    },
    "id": "HPtFzLcerAXe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9xmOUJ2BpAO"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1648474977376,
     "user": {
      "displayName": "Victor Machado Gonzaga",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14128796530531354520"
     },
     "user_tz": 180
    },
    "id": "Oj564N61otNS"
   },
   "outputs": [],
   "source": [
    "dataset = 'youtube' #@param ['youtube', 'mmmo', 'moud', 'pom'] {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59284,
     "status": "ok",
     "timestamp": 1648475036646,
     "user": {
      "displayName": "Victor Machado Gonzaga",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14128796530531354520"
     },
     "user_tz": 180
    },
    "id": "v49nOpPeuS1c",
    "outputId": "641f7e3f-c8bd-4e98-e9ad-3e49c55a7dd3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1_train = np.load(f'../data/{dataset}/X1_train.npy')\n",
    "X1_val = np.load(f'../data/{dataset}/X1_val.npy')\n",
    "X1_test = np.load(f'../data/{dataset}/X1_test.npy')\n",
    "X2_train = np.load(f'../data/{dataset}/X2_train.npy')\n",
    "X2_val = np.load(f'../data/{dataset}/X2_val.npy')\n",
    "X2_test = np.load(f'../data/{dataset}/X2_test.npy')\n",
    "y_train = np.load(f'../data/{dataset}/y_train.npy')\n",
    "y_val = np.load(f'../data/{dataset}/y_val.npy')\n",
    "y_test = np.load(f'../data/{dataset}/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KR6iwPyKLQNc"
   },
   "source": [
    "# Classificação apenas com features de imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kg7TG61KJRHi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def modal_image_classifier(df_data_train,df_data_test):\n",
    "  X = np.array( df_data_train['img_features'].to_list() )\n",
    "  y = np.array( df_data_train['intent'].to_list() )\n",
    "\n",
    "  clf_img = make_pipeline(StandardScaler(),MLPClassifier(random_state=1, max_iter=300))\n",
    "  clf_img.fit(X, y)\n",
    "\n",
    "  X_test = np.array( df_data_test['img_features'].to_list() )\n",
    "  y_test = np.array( df_data_test['intent'].to_list() )\n",
    "  return clf_img.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idbrp-8hLU2v"
   },
   "source": [
    "# Classificação apenas com features textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NreR1JkbKIhR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def modal_text_classifier(df_data_train,df_data_test):\n",
    "  X = np.array( df_data_train['text_features'].to_list() )\n",
    "  y = np.array( df_data_train['intent'].to_list() )\n",
    "  clf_text = make_pipeline(StandardScaler(),MLPClassifier(random_state=1, max_iter=300))\n",
    "  clf_text.fit(X, y)\n",
    "\n",
    "  X_test = np.array( df_data_test['text_features'].to_list() )\n",
    "  y_test = np.array( df_data_test['intent'].to_list() )\n",
    "  clf_text.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4N1JpOlH_Ox"
   },
   "source": [
    "# Multimodal Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ah360Fu93tso"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dot,Lambda,Input, Activation, Dense, Concatenate, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    " \n",
    "def autoencoder_att_labels(num_classes, size_1, size_2):\n",
    "    input_img = Input(shape=(size_1,))\n",
    "    input_txt = Input(shape=(size_2,))\n",
    "    fusion_dim = 512\n",
    " \n",
    "    im_emb = Activation('tanh')(input_img)\n",
    "    im_emb = Dense(fusion_dim, activation='tanh')(im_emb)\n",
    " \n",
    "    txt_emb = Activation('tanh')(input_txt)\n",
    "    txt_emb = Dense(fusion_dim, activation='tanh')(txt_emb)\n",
    " \n",
    "    ''' Attention Modality '''\n",
    "    #[input_1, input_2] = [visual_embd, average_seq]\n",
    "    input_1 = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(im_emb) # (bs, ndim)\n",
    "    input_2 = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(txt_emb) # (bs, ndim)\n",
    "    \n",
    "\n",
    "    output_size=1\n",
    "    # Step 1. Get scalar weights\n",
    "    scalar_input_1 = Dense(output_size)(input_1)  # (batch_size, output_size)\n",
    "    scalar_input_2 = Dense(output_size)(input_2)  # (batch_size, output_size)\n",
    "    scalar_input_1_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(scalar_input_1)  # (batch_size, output_size, 1)\n",
    "    scalar_input_2_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(scalar_input_2)  # (batch_size, output_size, 1)\n",
    "    scalars = concatenate([scalar_input_1_exp, scalar_input_2_exp], name='concat')  # (batch_size, output_size, 2)\n",
    "    \n",
    "    # # Step 2. Normalize weights - softmax\n",
    "    alphas = Activation('softmax')(scalars)  # (batch_size, output_size, 2)\n",
    "    \n",
    "    # Step 3. Weighted average\n",
    "    input_1_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(input_1)  # (batch_size, nb_feats, 1)\n",
    "    input_2_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(input_2)  # (batch_size, nb_feats, 1)\n",
    "    features = concatenate([input_1_exp, input_2_exp], name='concat_feats')  # (batch_size, nb_feats, 2)\n",
    " \n",
    "    latent = Dot(axes=[-1, -1])([alphas, features])  # (batch_size, output_size, nb_feats)\n",
    "    latent = tf.reduce_mean(latent, axis=1)\n",
    "    \n",
    "    encoder = Model([input_txt, input_img], [latent,alphas], name='encoder')\n",
    "    \n",
    "    clf_in = Input(shape=(fusion_dim,))\n",
    "    clf_probs = Dropout(0.4)(clf_in)\n",
    "    clf_probs = Dense(num_classes, activation='softmax')(clf_probs) # (batch_size, nb_labels)\n",
    "    clf = Model(clf_in, clf_probs, name='clf')\n",
    " \n",
    "    decoder_in = Input(shape=(fusion_dim,))\n",
    "    im_rebuild = Dense(fusion_dim, activation='tanh')(decoder_in)\n",
    "    im_rebuild = Dense(size_1, name='img_reb')(im_rebuild)\n",
    " \n",
    "    txt_rebuild = Dense(fusion_dim, activation='tanh')(decoder_in)\n",
    "    txt_rebuild = Dense(size_2, name='txt_reb')(txt_rebuild)\n",
    " \n",
    "    decoder = Model(decoder_in, outputs=[txt_rebuild,im_rebuild], name='decoder')\n",
    " \n",
    "    autoencoder = Model([input_txt, input_img], [decoder(encoder([input_txt, input_img])[0]), clf(encoder([input_txt, input_img])[0]) ] )\n",
    "\n",
    "    autoencoder.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=5e-4),\n",
    "                    loss=['mse','mse','categorical_crossentropy'],\n",
    "                    metrics=['accuracy'],\n",
    "                    loss_weights=[2.0,2.0,0.1]) # max_losses(512,512,~15) decoder_loss: 0.0021 - decoder_1_loss: 0.8902 - clf_loss: 1.8469\n",
    "\n",
    "    return clf, encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVbNFs7WSFC5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2woiRmjLl5T"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dot,Activation,Dense, Input, concatenate, multiply, average, subtract, add, Dropout, Lambda, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def clf_model(num_classes, size=256):\n",
    "    inp = Input(shape=(size))\n",
    "    x = Dense(size//2, activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(size//4, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(num_classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy', f1_m])\n",
    "    return model\n",
    "\n",
    "def multimodal_text_image(X_1,X_2,num_classes,operator='concatenate',verbose=0):\n",
    "\n",
    "  # fusion_dim = X_1.shape[1]+X_2.shape[1]\n",
    "  fusion_dim = X_1.shape[1]\n",
    "\n",
    "  inp1 = Input(shape=(X_1.shape[1]))\n",
    "  inp2 = Input(shape=(X_2.shape[1]))\n",
    "\n",
    "  l1 = Dense(fusion_dim, activation='relu')(inp1)\n",
    "  l2 = Dense(fusion_dim, activation='relu')(inp2)\n",
    "  # l1 = inp1\n",
    "  # l2 = inp2\n",
    "\n",
    "  # fusion layer\n",
    "  print('------->',operator)\n",
    "  if(operator=='concatenate'):\n",
    "    w = concatenate([l1,l2])\n",
    "  if(operator=='multiply'):\n",
    "    w = multiply([l1,l2])\n",
    "  if(operator=='average'):\n",
    "    w = average([l1,l2])\n",
    "  if(operator=='subtract'):\n",
    "    w = subtract([l1,l2])\n",
    "  if(operator=='add'):\n",
    "    w = add([l1,l2])\n",
    "  if(operator=='att'):\n",
    "    visual_embd = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(l1) # (bs, ndim)\n",
    "    average_seq = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(l2) # (bs, ndim)\n",
    "    scalar_visual = Dense(1)(visual_embd) # (bs, 1)\n",
    "    scalar_text = Dense(1)(average_seq) # (bs, 1)\n",
    "    scalars = concatenate([scalar_visual, scalar_text], name='concat')  # (bs, 2)\n",
    "\n",
    "    # # Step 2. Normalize weights - softmax\n",
    "    alphas = Activation('softmax')(scalars) # (bs, 2)\n",
    "\n",
    "    # Step 3. Weighted average\n",
    "    visual_embd_2 = Lambda( lambda x: tf.keras.backend.expand_dims(x) ) (visual_embd) # (bs, ndim, 1)\n",
    "    average_seq_2 = Lambda( lambda x: tf.keras.backend.expand_dims(x) )(average_seq) # (bs, ndim, 1)\n",
    "    features = concatenate([visual_embd_2, average_seq_2], name='concat_feats') # (bs, ndim, 2)\n",
    "    w = Dot(axes=[-1, -1])([alphas, features]) # (bs, ndim)\n",
    "  if(operator=='att_labels'):\n",
    "    #[input_1, input_2] = [visual_embd, average_seq]\n",
    "    input_1 = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(l1) # (bs, ndim)\n",
    "    input_2 = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(l2) # (bs, ndim)\n",
    "    output_size=num_classes\n",
    "    # Step 1. Get scalar weights\n",
    "    scalar_input_1 = Dense(output_size)(input_1)  # (batch_size, nb_labels)\n",
    "    scalar_input_2 = Dense(output_size)(input_2)  # (batch_size, nb_labels)\n",
    "    scalar_input_1_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(scalar_input_1)  # (batch_size, nb_labels, 1)\n",
    "    scalar_input_2_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(scalar_input_2)  # (batch_size, nb_labels, 1)\n",
    "    scalars = concatenate([scalar_input_1_exp, scalar_input_2_exp], name='concat')  # (batch_size, nb_labels, 2)\n",
    "    \n",
    "    # # Step 2. Normalize weights - softmax\n",
    "    alphas = Activation('softmax')(scalars)  # (batch_size, nb_labels, 2)\n",
    "    \n",
    "    # Step 3. Weighted average\n",
    "    input_1_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(input_1)  # (batch_size, nb_feats, 1)\n",
    "    input_2_exp = Lambda(lambda x: tf.keras.backend.expand_dims(x))(input_2)  # (batch_size, nb_feats, 1)\n",
    "    features = concatenate([input_1_exp, input_2_exp], name='concat_feats')  # (batch_size, nb_feats, 2)\n",
    "    w = Dot(axes=[-1, -1])([alphas, features])  # (batch_size, nb_labels, nb_feats)\n",
    "\n",
    "  w = Dropout(0.5)(w)\n",
    "  # fusion_layer = Dense(fusion_dim, activation='relu')(w)\n",
    "  fusion_layer = w\n",
    "\n",
    "  if (operator == 'att_labels'): # nm: new\n",
    "    output = Dense(1)(fusion_layer)  # (batch_size, nb_labels, 1)  \n",
    "    output = Lambda(lambda x: tf.keras.backend.squeeze(x, axis=-1))(output)  # (batch_size, nb_labels)\n",
    "    output = Activation('softmax')(output)  # (batch_size, nb_labels)    \n",
    "  else:\n",
    "    output = Dense(num_classes,activation='softmax')(fusion_layer)\n",
    "\n",
    "  model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "  \n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_m])\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  return model, fusion_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWk8p5n_bLXy"
   },
   "source": [
    "### Treinando e Avaliando o Multimodal Fusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-a5b-GjBSUy"
   },
   "source": [
    "Plot loss weights/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oazwkn8vW9nl"
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "from tqdm.notebook import tqdm\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "dataset_fold_path = 'documentIntent_emnlp19/splits/train_split_'\n",
    "merging_layers = ['autoencoder','image_emb', 'txt_emb', 'add', 'att_labels','att','concatenate','subtract','average','multiply']\n",
    "results = []\n",
    "seed = 0\n",
    "\n",
    "nb_folds = 5 # 5 | 1 (test)\n",
    "nb_runs = 1 # 11 | 2(test)\n",
    "\n",
    "for fold in tqdm(range(0,1)):\n",
    "\n",
    "  num_classes = y_train.shape[1]\n",
    "\n",
    "  \n",
    "  for merge in tqdm(merging_layers):\n",
    "    #X_train, X_test = None, NoneW\n",
    "    for run in range(0,nb_runs):\n",
    "        tf.random.set_seed(run)\n",
    "        #for lw in lws:\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=50,restore_best_weights=True, mode='max')\n",
    "        model,probs = None,None\n",
    "        if merge == 'autoencoder':\n",
    "          early_stopping = EarlyStopping(monitor='val_clf_accuracy', patience=100,restore_best_weights=True, mode='max')\n",
    "          clf, enc, dec, autoencoder = autoencoder_att_labels(num_classes, X2_train.shape[1], X1_train.shape[1])\n",
    "          autoencoder.fit([X1_train, X2_train], [[X1_train, X2_train], y_train], validation_data=([X1_val, X2_val], [[X1_val, X2_val], y_val]), epochs=1000, batch_size=64, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "          encoded, _ = enc([X1_test, X2_test])\n",
    "          probs = clf.predict(encoded)\n",
    "        elif merge == 'txt_emb':\n",
    "          model = clf_model(num_classes, size=X1_train.shape[1])\n",
    "          model.fit(X1_train, y_train, epochs=1000,batch_size=16, verbose=0, validation_data=(X1_val, y_val), callbacks=[early_stopping])\n",
    "          probs = model.predict(X1_test)\n",
    "        elif merge == 'image_emb':\n",
    "          model = clf_model(num_classes, size=X2_train.shape[1])\n",
    "          model.fit(X2_train, y_train, epochs=1000,batch_size=16, verbose=0, validation_data=(X2_val, y_val), callbacks=[early_stopping])\n",
    "          probs = model.predict(X2_test)\n",
    "        else:\n",
    "          model, fusion_layer = multimodal_text_image(X1_train,X2_train,num_classes,operator=merge)\n",
    "          model.fit([X1_train,X2_train], y_train, validation_data=([X1_val, X2_val], y_val),\n",
    "                          epochs=1000,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True,verbose=0, callbacks=[early_stopping])\n",
    "          probs = model.predict([X1_test,X2_test])\n",
    "\n",
    "        y_true = np.argmax(y_test,axis=1)\n",
    "        y_pred = np.argmax(probs,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_test, probs, average='macro', multi_class='ovr')\n",
    "\n",
    "        print(fold,merge, acc,f1_micro,f1_macro,auc)\n",
    "        results.append((fold,merge, acc, f1_micro,f1_macro,auc,10.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVft2n6duta-"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_bh6kQAoX0O"
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.columns = ['fold','merging','acc','f1-micro','f1-macro','auc', 'clf_weight']\n",
    "df_results\n",
    "df = df_results.groupby(['merging','fold'], as_index=False).agg(\n",
    "                      {'acc':['mean','std']})\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5YfGNic348K"
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by='acc', ascending=False)[df_results.fold==0].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp43f1im4OiL"
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by='acc', ascending=False)[df_results.fold==1].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJpm86iB4Tny"
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by='acc', ascending=False)[df_results.fold==2].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HarXHTba4Zsl"
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by='acc', ascending=False)[df_results.fold==3].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ujePTO04d-s"
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by='acc', ascending=False)[df_results.fold==4].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow0bl7ho3CfX"
   },
   "outputs": [],
   "source": [
    "sorted(df_results.to_numpy().tolist(), reverse=True, key=lambda a: a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAhJ6h_C3Cp_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results.to_excel(f'{dataset}_fusion_models_seeded.xls')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multimodal_Early_Fusion_Model_for_C4AI_DS_EarlyFusion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
